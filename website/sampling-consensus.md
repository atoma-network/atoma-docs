# Atoma Network Sampling Consensus

The Atoma Network relies on a newly designed protocol to reach consensus on the output state generated by Atoma Network nodes, which we refer to as `Sampling Consensus`. Such protocol
allows the Atoma Network to provide high verifiability guarantees on the execution of any computation being executed by its nodes. This means, that workflows running on the Atoma Network
can be used to enhance smart contracts. We believe that the Atoma Network technology will open the doors to the next generation of applications being built in both Web3 and Web2. 

We will delve deeper in the inner workings of Atoma's Sampling Consensus algorithm and how it compares with other methods that can potentially lead to verifiability of AI compute. 

##  Issue with Trust 

In a permissionless network, no assumptions can be made about the accuracy of the AI generated output.  If we ask the network to run inference using a 70 billion parameter model, such as Llama2-70B, how can we be assured that itâ€™s not actually using a much smaller model, such as the 13 billion parameter model LLama2-13B? 

Verifiable AI inference ensures that models not only respond to prompts but it also provide high guarantees that the generated output was correctly derived from the desired model and inputs. 

Any Web3 user can relate this need with the fact that decentralized technologies (such as blockchains) often times rely on high compute replication to reach this high assurance degree on
the execution of submitted transactions. The way that most current blockchains resolve this issue is through a high degree of replication, through a consensus protocol. That said, blockchains
often have hundreds if not thousands of validators. This implies that a single transaction has to be executed at least by a supra majority of nodes (often two thirds of the nodes in the network).

Therefore, maximum individual transaction size for blockchains consists of only a few kilobytes, whereas most modern AI models require gigabytes of memory to be executed. For this reason, it is not feasible to run AI inference on-chain (even if we could increase the transaction size, the cost of replication would be tremendous making it inaccessible in the supra majority of use cases). It follows that we have to look into alternative methods of verification. 

## Overview on Verifiable Computation Algorithms  

###  Byzantine Fault Tolerant Protocols

Byzantine Fault Tolerant consensus (BFT) refers to a class of algorithms used in distributed systems to agree on the state of a global ledger being altered by a given transaction. Consensus among nodes in the decentralized protocol can be reached even if a proportion of the nodes in the system are unreliable or malicious. BFT consensus ensures that even if some participants are unreliable, the system as a whole can still make a reliable and unanimous decision.

The issue with BFT consensus is that the large majority of nodes (usually around 2/3rds) must agree on a transaction or block of transactions.

In the context of AI inference, BFT methods require heavy compute distributed across many nodes with each node performing the same computations independently. Not only that but, usually BFT consensus require multiple rounds of communication among a supra-majority of participating nodes. Given the fact that AI compute pipelines generate large amounts of intermediate state data, this fact along contributes to a extremely large computational power, latency, and scalability overhead.

###  Zero Knowledge Machine Learning 

Zero knowledge machine learning (ZKML) is the application of zero knowledge proofs (ZKPs) to AI and machine learning models to ensure that the results of the machine learning models are correct. The details of the machine learning model itself (like the model weights) can remain confidential. This is because, model owners can keep their models self-hosted (without disclosing model
weights) and still provide zk proofs for each executed request. If such proof is valid, the probability that the execution was incorrectly done is orders of magnitude smaller than the fraction of the total number of atoms in the universe.
 
Even though such property is highly desirable in practice, ZKML also leads to a tremendous large overhead compared to native AI model execution. Running a proof for medium models is much slower because of all the cryptographic redudancy one needs to introduce into generating these proofs. Essentially, compiling a deep neural network into zk circuits for proofs is incredibly expensive and difficult. Moreover, at the time of writing, we are still yet to see any zk proof generation deployment for any large language model (LLM).

That said, even though with incredible potential, given the demand for inference, ZKML is not scalable enough to offer fast and low cost results. 

###  Optimistic Machine Learning (OpML) 

OpML assumes everything is correct unless proven otherwise. Systems operate assuming computations are valid which initially is more efficient because it avoids the cost and delays incurred by immediate verification

In order to verify the state of a given computation however, OpML has challenge periods which are specific time windows where participants in the system can challenge the validity of a computation and if a challenge is validated, a correction is made to ensure accuracy. 

These challenge periods lead to delays in finalizing computations because they allow time for challenges to be raised and resolved. The delay can vary in length preventing immediate finality. 

Immediate finality ensures that once a computation is confirmed, it is considered complete and valid across the entire system. Challenge periods delay this finality leading to inconsistent states if challenges alter the initial assumptions. The outcome of a computation might change after assuming correctness which disrupts any subsequent operations. 

OpML isn't an optimal protocol for rewarding nodes either. This boils to the fact that verifiers need to confirm the outputs by computing them, while only receiving rewards in the case a dispute is resolved in their favour.  

###  Atoma's Sampling Consensus

Atoma has developed a novel sampling consensus protocol that eliminates most of the aforementioned issues. The way it operates is as follows:

In order to process requests, the Atoma Network protocol selects a given number of nodes uniformly at random. The selected nodes must execute the given requests, otherwise part of their collateral value is at risk of being slashed. 

The selected nodes are guaranteed to have identical hardware and software specifications and the node sampling mechanism is part of our sampling consensus protocol. 

The Atoma Network sampling consensus protocol satisfies the following: 

1.  Load balancing of the request volume across the Atoma Network. 
- Requests are only executed across nodes with specific hardware capacities, this node selection homogenizes the balancing of the request load on the Atoma Network.

2.  Nodes reach deterministic agreement on the state of the output generated by executing the given request through the selection mechanism. 
- All selected nodes will generate the same outputs given the same inputs and the same workload (specified by the incoming request). This is especially important for workloads that rely on floating point arithmetic, the latter being highly non-deterministic.
- In the case for AI inference, there is a crucial dependence on floating point arithmetic (specially for LLM inference). By selecting nodes with the same hardware specifications (such as the same GPU card), determinism of floating point arithmetic is guaranteed (with potential mild changes to the kernels which the code runs into). 
- This is especially relevant to enforce verifiable compute. 

3.  Whenever two or more nodes are selected to execute a request, the selected nodes disagree if at least one of the nodes has been dishonest. 
- In particular, an honest node will never agree on the state of a request output with the dishonest one.

## Probabilistic Considerations for Atoma's Sampling Consensus

As previously mentioned, the Atoma protocol can enforce determinism for execution workloads (a.k.a requests) by replicating compute. It does this by randomly selecting a given number of nodes to run the same compute.

Depending on the number of sampled nodes, different levels of output integrity are achieved. For example, assuming a dishonest participant of the Atoma Network controls a percentage r of the network, the probability, P, that a quorum of N > 0 selected nodes (including at least one of the dishonest participant nodes) is:

\[ P = r^N. \]

In particular, if \( N = 5 \) nodes are selected and the dishonest participant controls one third of the network, that is \( r = \frac{1}{3} \), the probability above becomes

\[ P = \left(\frac{1}{3}\right)^5 = 0.00411\ldots \]

With \( N = 10 \), the probability becomes

\[ P = \left(\frac{1}{3}\right)^{10} = 1.6935 \times 10^{-5}, \]

We can see that even a small set of nodes, selected uniformly at random, can lead to very high trust guarantees that a given generated output has not been tampered with, in any possible form.


## Cross validation mechanism

## Node obfuscation


