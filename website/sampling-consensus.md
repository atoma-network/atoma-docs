# Atoma Network Sampling Consensus

The Atoma Network relies on a newly designed protocol to reach consensus on the output state generated by Atoma Network nodes, which we refer to as `Sampling Consensus`. Such protocol
allows the Atoma Network to provide high verifiability guarantees on the execution of any computation being executed by its nodes. This means, that workflows running on the Atoma Network
can be used to enhance smart contracts. We believe that the Atoma Network technology will open the doors to the next generation of applications being built in both Web3 and Web2. 

We will delve deeper in the inner workings of Atoma's Sampling Consensus algorithm and how it compares with other methods that can potentially lead to verifiability of AI compute. 

##  Issue with Trust 

In a permissionless network, no assumptions can be made about the accuracy of the AI generated output.  If we ask the network to run inference using a 70 billion parameter model, such as Llama2-70B, how can we be assured that it’s not actually using a much smaller model, such as the 13 billion parameter model LLama2-13B? 

Verifiable AI inference ensures that models not only respond to prompts but it also provide high guarantees that the generated output was correctly derived from the desired model and inputs. 

Any Web3 user can relate this need with the fact that decentralized technologies (such as blockchains) often times rely on high compute replication to reach this high assurance degree on
the execution of submitted transactions. The way that most current blockchains resolve this issue is through a high degree of replication, through a consensus protocol. That said, blockchains
often have hundreds if not thousands of validators. This implies that a single transaction has to be executed at least by a supra majority of nodes (often two thirds of the nodes in the network).

Therefore, maximum individual transaction size for blockchains consists of only a few kilobytes, whereas most modern AI models require gigabytes of memory to be executed. For this reason, it is not feasible to run AI inference on-chain (even if we could increase the transaction size, the cost of replication would be tremendous making it inaccessible in the supra majority of use cases). It follows that we have to look into alternative methods of verification. 

## Overview on Verifiable Computation Algorithms  

###  Byzantine Fault Tolerant Protocols

Byzantine Fault Tolerant consensus (BFT) refers to a class of algorithms used in distributed systems to agree on the state of a global ledger being altered by a given transaction. Consensus among nodes in the decentralized protocol can be reached even if a proportion of the nodes in the system are unreliable or malicious. BFT consensus ensures that even if some participants are unreliable, the system as a whole can still make a reliable and unanimous decision.

The issue with BFT consensus is that the large majority of nodes (usually around 2/3rds) must agree on a transaction or block of transactions.

In the context of AI inference, BFT methods require heavy compute distributed across many nodes with each node performing the same computations independently. Not only that but, usually BFT consensus require multiple rounds of communication among a supra-majority of participating nodes. Given the fact that AI compute pipelines generate large amounts of intermediate state data, this fact along contributes to a extremely large computational power, latency, and scalability overhead.

###  Zero Knowledge Machine Learning 

Zero knowledge machine learning (ZKML) is the application of zero knowledge proofs (ZKPs) to AI and machine learning models to ensure that the results of the machine learning models are correct. The details of the machine learning model itself (like the model weights) can remain confidential. This is because, model owners can keep their models self-hosted (without disclosing model
weights) and still provide zk proofs for each executed request. If such proof is valid, the probability that the execution was incorrectly done is orders of magnitude smaller than the fraction of the total number of atoms in the universe.
 
Even though such property is highly desirable in practice, ZKML also leads to a tremendous large overhead compared to native AI model execution. Running a proof for medium models is much slower because of all the cryptographic redudancy one needs to introduce into generating these proofs. Essentially, compiling a deep neural network into zk circuits for proofs is incredibly expensive and difficult. Moreover, at the time of writing, we are still yet to see any zk proof generation deployment for any large language model (LLM).

That said, even though with incredible potential, given the demand for inference, ZKML is not scalable enough to offer fast and low cost results. 

###  Optimistic Machine Learning (OpML) 

OpML assumes everything is correct unless proven otherwise. Systems operate assuming computations are valid which initially is more efficient because it avoids the cost and delays incurred by immediate verification

In order to verify the state of a given computation however, OpML has challenge periods which are specific time windows where participants in the system can challenge the validity of a computation and if a challenge is validated, a correction is made to ensure accuracy. 

These challenge periods lead to delays in finalizing computations because they allow time for challenges to be raised and resolved. The delay can vary in length preventing immediate finality. 

Immediate finality ensures that once a computation is confirmed, it is considered complete and valid across the entire system. Challenge periods delay this finality leading to inconsistent states if challenges alter the initial assumptions. The outcome of a computation might change after assuming correctness which disrupts any subsequent operations. 

OpML isn't an optimal protocol for rewarding nodes either. This boils to the fact that verifiers need to confirm the outputs by computing them, while only receiving rewards in the case a dispute is resolved in their favour.  

###  Atoma's Sampling Consensus

Atoma has developed a novel sampling consensus protocol that eliminates most of the aforementioned issues. The way it operates is as follows:

In order to process requests, the Atoma Network protocol selects a given number of nodes uniformly at random. The selected nodes must execute the given requests, otherwise part of their collateral value is at risk of being slashed. 

The selected nodes are guaranteed to have identical hardware and software specifications and the node sampling mechanism is part of our sampling consensus protocol. 

The Atoma Network sampling consensus protocol satisfies the following: 

1.  Load balancing of the request volume across the Atoma Network. 
- Requests are only executed across nodes with specific hardware capacities, this node selection homogenizes the balancing of the request load on the Atoma Network.

2.  Nodes reach deterministic agreement on the state of the output generated by executing the given request through the selection mechanism. 
- All selected nodes will generate the same outputs given the same inputs and the same workload (specified by the incoming request). This is especially important for workloads that rely on floating point arithmetic, the latter being highly non-deterministic.
- In the case for AI inference, there is a crucial dependence on floating point arithmetic (specially for LLM inference). By selecting nodes with the same hardware specifications (such as the same GPU card), determinism of floating point arithmetic is guaranteed (with potential mild changes to the kernels which the code runs into). 
- This is especially relevant to enforce verifiable compute. 

3.  Whenever two or more nodes are selected to execute a request, the selected nodes disagree if at least one of the nodes has been dishonest. 
- In particular, an honest node will never agree on the state of a request output with a dishonest one. Finally, independent nodes can only come to consensus if all of them
have performed the requested computation honestly.

4. Each request specifies a given timeout period, in which case if a node times out, it gets some collateral percentage slashed.

5. Atoma's Sampling Consensus has almost native finality times. Indeed, the fastest execution node in a sampled quorum can immediately share the output with the user (either via a web browser RTC connection, decentralized data storage, or even if a blockchain if the output is both public and small, etc). The final verifiability attestation (which ensures the computation was not
tampered in any form) is provided at the time the slowest node commits to the output. From 1. it follows that nodes executing a request have similar hardware specifications, which in theory means that the difference between the fastest and slowest processing nodes should be mostly from bandwidth speed variability. This means that contrary to OpML, Atoma Sampling Consensus has no
challenge period.


## Probabilistic Considerations for Atoma's Sampling Consensus

As previously mentioned, the Atoma protocol can enforce determinism for execution workloads (a.k.a requests) by replicating compute. It does this by randomly selecting a given number of nodes to run the same compute.

Depending on the number of sampled nodes, different levels of output integrity are achieved. For example, assuming a dishonest participant of the Atoma Network controls a percentage $r$ of the network, the probability, $P$, that a quorum of $N > 0$ selected nodes (including at least one of the dishonest participant nodes) is:

$P = r^N.$

In particular, if $N = 5$ nodes are selected and the dishonest participant controls one third of the network, that is $r = \frac{1}{3}$, the probability above becomes

$P = \left(\frac{1}{3}\right)^5 = 4.11×10^{−3}\ldots$

With $N = 10$, the probability becomes

$P = \left(\frac{1}{3}\right)^{10} = 1.6935 \times 10^{-5},$

We can see that even a small set of nodes, selected uniformly at random, can lead to very high trust guarantees that a given generated output has not been tampered with, in any possible form.
That said, if a user requires high guarantee trust on the state of a given output, through Atoma, it must pay $N$ times the native cost. For many use cases such additional replication cost
is not an issue. For example, if a the AI inference provides an automation trading strategy that can generate additional revenue for a given DeFi protocol, paying $N$ times the native execution
to have full guarantee that the output is not maliciously generated is totally feasible, especially as processing such request natively might only cost a few cents. 

We also want to highlight that every verifiability algorithm mentioned previously (including ZKML and OpML) leads to an higher cost compared to native execution. It is hypothesized that ZKML
proof generation can be up to 10,000x  the cost of native execution for medium size models, and the future goal is to get up to a reduction to only 20x execution overhead cost. On the other hand,
OpML requires at least one verifier to attest the computations being generated in the network. As mentioned above, if no disputes are being made in the protocol, the amount of additional reward for nodes needs to be high enough to be economically feasible for nodes to collectively verify each inference request in the network. 

Finally, there are other use
cases to which verifiability is still necessary, but paying such additional cost is not desirable. Such use cases amount to low to medium verifiability needs. For example, a chat-bot community
application, an AI NFT enhancement protocol, etc. In order to tackle these examples and reduce costs, we have introduced the following two improvements on our original Sampling Consensus protocol:

## Cross Validation Sampling Consensus

In order to address the replication costs within the original `Sampling Consensus`, we have put forth a slightly different protocol algorithm which we refer to `Cross Validation Sampling Consensus` which allows for considerably lower costs, with a slight impact on verifiability.

The way Cross Validation Sampling Consensus works is as follows:

1. For each incoming request onto Atoma Network, a single randomly chosen node is assigned to execute the request.
2. Once the node commits to the generated output, we select a quorum of $N$ nodes with probability $p$. If nodes are not selected (wit probability $1 - p$) then the committed output 
by the initial node is considered to final. Otherwise, the selected $N$ nodes provide their own output commitments. If these agree with the original node's output commitment, then
the result is considered to be final, otherwise, a dispute is set forth.
3. Once the dispute is resolved, the collateral of maliciously generated output nodes is distributed among those nodes in the quorum of $N + 1$ (the original node plus the later selected $N$ nodes) that committed to the correct output.

As explained above, the Cross Validation Sampling Consensus only relies on replication with rate $0 < p < 1$. This means, that a percentage of $(1-p)x100%$ of times, requests are executed
by a single node. The interesting feature of this approach is that a node has no way to predict if its output will be attested by other $N$ nodes or not (unless the node has access to the
random oracle used for random sampling).


## Node obfuscation


