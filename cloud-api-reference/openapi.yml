openapi: 3.1.0
info:
  title: atoma-proxy
  description: ''
  license:
    name: Apache-2.0
    identifier: Apache-2.0
  version: 0.1.0
servers:
- url: https://api.atoma.network
paths:
  /v1/chat/completions:
    post:
      tags:
      - Chat
      summary: Create chat completion
      description: |-
        This function processes chat completion requests by determining whether to use streaming
        or non-streaming response handling based on the request payload. For streaming requests,
        it configures additional options to track token usage.

        ## Returns

        Returns a Response containing either:
        - A streaming SSE connection for real-time completions
        - A single JSON response for non-streaming completions

        ## Errors

        Returns an error status code if:
        - The request processing fails
        - The streaming/non-streaming handlers encounter errors
        - The underlying inference service returns an error
      operationId: chat_completions_create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
        required: true
      responses:
        '200':
          description: Chat completions
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /v1/chat/completions#stream:
    post:
      tags:
      - Chat
      operationId: chat_completions_create_stream
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionStreamRequest'
        required: true
      responses:
        '200':
          description: Chat completions
          content:
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ChatCompletionStreamResponse'
              x-speakeasy-sse-sentinel: '[DONE]'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /v1/confidential/chat/completions:
    post:
      tags:
      - Confidential Chat
      summary: Create confidential chat completion
      description: |-
        This handler processes chat completion requests in a confidential manner, providing additional
        encryption and security measures for sensitive data processing. It supports both streaming and
        non-streaming responses while maintaining data confidentiality through AEAD encryption and TEE hardware,
        for full private AI compute.

        ## Returns

        Returns a `Result` containing either:
        * An HTTP response with the chat completion result
        * A streaming SSE connection for real-time completions
        * An `AtomaProxyError` error if the request processing fails

        ## Errors

        Returns `AtomaProxyError::InvalidBody` if:
        * The 'stream' field is missing or invalid in the payload

        Returns `AtomaProxyError::InternalError` if:
        * The inference service request fails
        * Response processing encounters errors
        * State manager updates fail

        ## Security Features

        * Utilizes AEAD encryption for request/response data
        * Supports TEE (Trusted Execution Environment) processing
        * Implements secure key exchange using X25519
        * Maintains confidentiality throughout the request lifecycle
      operationId: confidential_chat_completions_create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ConfidentialComputeRequest'
        required: true
      responses:
        '200':
          description: Confidential chat completions
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConfidentialComputeResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /v1/confidential/chat/completions#stream:
    post:
      tags:
      - Confidential Chat
      operationId: confidential_chat_completions_create_stream
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ConfidentialComputeRequest'
        required: true
      responses:
        '200':
          description: Chat completions
          content:
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ConfidentialComputeStreamResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /v1/confidential/embeddings:
    post:
      tags:
      - Confidential Embeddings
      summary: Create confidential embeddings
      description: |-
        This endpoint follows the OpenAI API format for generating vector embeddings from input text,
        but with confidential processing (through AEAD encryption and TEE hardware).
        The handler receives pre-processed metadata from middleware and forwards the request to
        the selected node.

        ## Returns
        * `Ok(Response)` - The embeddings response from the processing node
        * `Err(AtomaProxyError)` - An error status code if any step fails

        ## Errors
        * `INTERNAL_SERVER_ERROR` - Processing or node communication failures
      operationId: confidential_embeddings_create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ConfidentialComputeRequest'
        required: true
      responses:
        '200':
          description: Confidential embeddings generated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConfidentialComputeResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /v1/confidential/images/generations:
    post:
      tags:
      - Confidential Images
      summary: Create confidential image
      description: |-
        This handler processes image generation requests in a confidential manner, providing additional
        encryption and security measures for sensitive data processing. It supports both streaming and
        non-streaming responses while maintaining data confidentiality through AEAD encryption and TEE hardware,
        for full private AI compute.
      operationId: confidential_image_generations_create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ConfidentialComputeRequest'
        required: true
      responses:
        '200':
          description: Image generations
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConfidentialComputeResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /v1/embeddings:
    post:
      tags:
      - Embeddings
      summary: Create embeddings
      description: |-
        This endpoint follows the OpenAI API format for generating vector embeddings from input text.
        The handler receives pre-processed metadata from middleware and forwards the request to
        the selected node.

        # Returns
        * `Ok(Response)` - The embeddings response from the processing node
        * `Err(AtomaProxyError)` - An error status code if any step fails

        ## Errors
        * `INTERNAL_SERVER_ERROR` - Processing or node communication failures
      operationId: embeddings_create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEmbeddingRequest'
        required: true
      responses:
        '200':
          description: Embeddings generated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateEmbeddingResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /health:
    get:
      tags:
      - Health
      summary: Health
      operationId: health
      responses:
        '200':
          description: Service is healthy
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HealthResponse'
        '500':
          description: Service is unhealthy
  /v1/images/generations:
    post:
      tags:
      - Images
      summary: Create image
      description: |-
        This endpoint processes requests to generate images using AI models by forwarding them
        to the appropriate AI node. The request metadata and compute units have already been
        validated by middleware before reaching this handler.

        ## Errors
        * Returns various status codes based on the underlying `handle_image_generation_response`:
          - `INTERNAL_SERVER_ERROR` - If there's an error communicating with the AI node
      operationId: image_generations_create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateImageRequest'
        required: true
      responses:
        '200':
          description: Image generations
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateImageResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /v1/models:
    get:
      tags:
      - Models
      summary: List models
      description: |-
        This endpoint mimics the OpenAI models endpoint format, returning a list of
        available models with their associated metadata. Each model includes standard
        OpenAI-compatible fields to ensure compatibility with existing OpenAI client libraries.
      operationId: models_list
      responses:
        '200':
          description: List of available models
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelList'
        '500':
          description: Failed to retrieve list of available models
  /v1/nodes:
    post:
      tags:
      - Nodes
      summary: Create node
      description: |-
        This endpoint allows nodes to register or update their public address in the system.
        When a node comes online or changes its address, it can use this endpoint to ensure
        the system has its current address for routing requests.

        ## Errors

        Returns various `AtomaProxyError` variants:
        * `MissingHeader` - If the signature header is missing
        * `InvalidHeader` - If the signature header is malformed
        * `InvalidBody` - If:
          - The request body cannot be read
          - The signature is invalid
          - The body cannot be parsed
          - The sui address doesn't match the signature
        * `InternalError` - If:
          - The state manager channel is closed
          - The registration event cannot be sent
          - Node Sui address lookup fails
      operationId: nodes_create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/NodesCreateRequest'
        required: true
      responses:
        '200':
          description: Node public address registered successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/NodesCreateResponse'
        '500':
          description: Failed to register node public address
  /v1/nodes/lock:
    post:
      tags:
      - Nodes
      summary: Create a node lock for confidential compute
      description: |-
        This endpoint attempts to find a suitable node and retrieve its public key for encryption
        through a two-step process:

        1. First, it tries to select an existing node with a public key directly.
        2. If no node is immediately available, it falls back to finding the cheapest compatible node
           and acquiring a new stack entry for it.

        This endpoint is specifically designed for confidential compute scenarios where
        requests need to be encrypted before being processed by nodes.

        ## Errors
          - `INTERNAL_SERVER_ERROR` - Communication errors or missing node public keys
          - `SERVICE_UNAVAILABLE` - No nodes available for confidential compute
      operationId: nodes_create_lock
      requestBody:
        description: The model to lock a node for
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/NodesCreateLockRequest'
        required: true
      responses:
        '200':
          description: Node DH public key requested successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/NodesCreateLockResponse'
        '500':
          description: Failed to request node DH public key
        '503':
          description: No node found for model with confidential compute enabled for requested model
      security:
      - bearerAuth: []
components:
  schemas:
    ChatCompletionChoice:
      type: object
      description: |-
        Represents the chat completion choice.

        This is used to represent the chat completion choice in the chat completion request.
        It can be either a chat completion message or a chat completion chunk.
      required:
      - index
      - message
      properties:
        finish_reason:
          type:
          - string
          - 'null'
          description: The reason the chat completion was finished.
          example: stop
        index:
          type: integer
          format: int32
          description: The index of this choice in the list of choices.
          example: 0
        logprobs:
          oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/ChatCompletionLogProbs'
            description: Log probability information for the choice, if applicable.
        message:
          $ref: '#/components/schemas/ChatCompletionMessage'
          description: The chat completion message.
    ChatCompletionChunk:
      type: object
      description: |-
        Represents the chat completion chunk.

        This is used to represent the chat completion chunk in the chat completion request.
        It can be either a chat completion chunk or a chat completion chunk choice.
      required:
      - id
      - object
      - created
      - model
      - choices
      properties:
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionChunkChoice'
          description: A list of chat completion chunk choices.
        created:
          type: integer
          format: int64
          description: The Unix timestamp (in seconds) of when the chunk was created.
          example: 1677652288
        id:
          type: string
          description: A unique identifier for the chat completion chunk.
          example: chatcmpl-123
        model:
          type: string
          description: The model used for the chat completion.
          example: meta-llama/Llama-3.3-70B-Instruct
        object:
          type: string
          description: The object of the chat completion chunk (which is always `chat.completion.chunk`)
          example: chat.completion.chunk
        usage:
          oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/CompletionUsage'
            description: Usage statistics for the completion request.
    ChatCompletionChunkChoice:
      type: object
      description: |-
        Represents the chat completion chunk choice.

        This is used to represent the chat completion chunk choice in the chat completion request.
      required:
      - index
      - delta
      properties:
        delta:
          $ref: '#/components/schemas/ChatCompletionChunkDelta'
          description: The chat completion delta message for streaming.
        finish_reason:
          type:
          - string
          - 'null'
          description: The reason the chat completion was finished, if applicable.
          example: stop
        index:
          type: integer
          format: int32
          description: The index of this choice in the list of choices.
          example: 0
        logprobs:
          oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/ChatCompletionLogProbs'
            description: Log probability information for the choice, if applicable.
        stop_reason:
          oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/StopReason'
            description: The reason the chat completion was stopped, if applicable.
    ChatCompletionChunkDelta:
      type: object
      description: |-
        Represents the chat completion chunk delta.

        This is used to represent the chat completion chunk delta in the chat completion request.
        It can be either a chat completion chunk delta message or a chat completion chunk delta choice.
      properties:
        content:
          type:
          - string
          - 'null'
          description: The content of the message, if present in this chunk.
          example: Hello
        reasoning_content:
          type:
          - string
          - 'null'
          description: The reasoning content, if present in this chunk.
        role:
          type:
          - string
          - 'null'
          description: The role of the message author, if present in this chunk.
          example: assistant
        tool_calls:
          type:
          - array
          - 'null'
          items:
            $ref: '#/components/schemas/ChatCompletionChunkDeltaToolCall'
          description: The tool calls information, if present in this chunk.
    ChatCompletionChunkDeltaToolCall:
      type: object
      description: |-
        Represents the chat completion chunk delta tool call.

        This is used to represent the chat completion chunk delta tool call in the chat completion request.
        It can be either a chat completion chunk delta tool call or a chat completion chunk delta tool call function.
      required:
      - id
      - type
      - index
      properties:
        function:
          oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/ChatCompletionChunkDeltaToolCallFunction'
            description: The function of the tool call.
        id:
          type: string
          description: The ID of the tool call.
        index:
          type: integer
          format: int32
          description: The index of the tool call.
        type:
          type: string
          description: The type of the tool call.
    ChatCompletionChunkDeltaToolCallFunction:
      type: object
      description: |-
        Represents the chat completion chunk delta tool call function.

        This is used to represent the chat completion chunk delta tool call function in the chat completion request.
        It can be either a chat completion chunk delta tool call function or a chat completion chunk delta tool call function arguments.
      properties:
        arguments:
          type:
          - string
          - 'null'
          description: The arguments of the tool call function.
        name:
          type:
          - string
          - 'null'
          description: The name of the tool call function.
    ChatCompletionLogProb:
      type: object
      description: |-
        Represents the chat completion log prob.

        This is used to represent the chat completion log prob in the chat completion request.
        It can be either a chat completion log prob or a chat completion log prob choice.
      required:
      - logprob
      - token
      properties:
        bytes:
          type:
          - array
          - 'null'
          items:
            type: integer
            format: int32
          description: |-
            A list of integers representing the UTF-8 bytes representation of the token.
            Useful in instances where characters are represented by multiple tokens and their byte
            representations must be combined to generate the correct text representation.
            Can be null if there is no bytes representation for the token.
        logprob:
          type: number
          format: float
          description: The log prob of the chat completion.
        token:
          type: string
          description: The token of the chat completion.
    ChatCompletionLogProbs:
      type: object
      description: |-
        Represents the chat completion log probs.

        This is used to represent the chat completion log probs in the chat completion request.
        It can be either a chat completion log probs or a chat completion log probs choice.
      properties:
        content:
          type:
          - array
          - 'null'
          items:
            $ref: '#/components/schemas/ChatCompletionLogProbsContent'
          description: The log probs of the chat completion.
    ChatCompletionLogProbsContent:
      type: object
      description: |-
        Represents the chat completion log probs content.

        This is used to represent the chat completion log probs content in the chat completion request.
        It can be either a chat completion log probs content or a chat completion log probs content choice.
      required:
      - top_logprobs
      properties:
        top_logprobs:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionLogProb'
    ChatCompletionMessage:
      oneOf:
      - type: object
        description: The role of the messages author, in this case system.
        required:
        - role
        properties:
          content:
            oneOf:
            - type: 'null'
            - $ref: '#/components/schemas/MessageContent'
              description: The contents of the message.
          name:
            type:
            - string
            - 'null'
            description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
          role:
            type: string
            enum:
            - system
      - type: object
        description: The role of the messages author, in this case user.
        required:
        - role
        properties:
          content:
            oneOf:
            - type: 'null'
            - $ref: '#/components/schemas/MessageContent'
              description: The contents of the message.
          name:
            type:
            - string
            - 'null'
            description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
          role:
            type: string
            enum:
            - user
      - type: object
        description: The role of the messages author, in this case assistant.
        required:
        - role
        properties:
          content:
            oneOf:
            - type: 'null'
            - $ref: '#/components/schemas/MessageContent'
              description: The contents of the message.
          name:
            type:
            - string
            - 'null'
            description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
          refusal:
            type:
            - string
            - 'null'
            description: The refusal message by the assistant.
          role:
            type: string
            enum:
            - assistant
          tool_calls:
            type: array
            items:
              $ref: '#/components/schemas/ToolCall'
            description: The tool calls generated by the model, such as function calls.
      - type: object
        description: The role of the messages author, in this case tool.
        required:
        - role
        properties:
          content:
            oneOf:
            - type: 'null'
            - $ref: '#/components/schemas/MessageContent'
              description: The contents of the message.
          role:
            type: string
            enum:
            - tool
          tool_call_id:
            type: string
            description: Tool call that this message is responding to.
      description: |-
        A message that is part of a conversation which is based on the role
        of the author of the message.

        This is used to represent the message in the chat completion request.
        It can be either a system message, a user message, an assistant message, or a tool message.
    ChatCompletionNamedFunction:
      type: object
      description: |-
        A named function that can be used in a chat completion.

        This is used to represent the named function in the chat completion request.
      required:
      - name
      properties:
        name:
          type: string
          description: The name of the function.
    ChatCompletionNamedToolChoiceParam:
      type: object
      description: |-
        A named tool choice that can be used in a chat completion.

        This is used to represent the named tool choice in the chat completion request.
      required:
      - type
      - function
      properties:
        function:
          $ref: '#/components/schemas/ChatCompletionNamedFunction'
          description: The function of the tool choice.
        type:
          type: string
          description: The type of the tool choice.
    ChatCompletionRequest:
      type: object
      description: |-
        Represents the chat completion request.

        This is used to represent the chat completion request in the chat completion request.
        It can be either a chat completion or a chat completion stream.
      required:
      - model
      - messages
      properties:
        frequency_penalty:
          type:
          - number
          - 'null'
          format: float
          description: |-
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their
            existing frequency in the text so far
          example: 0.0
        function_call:
          description: Controls how the model responds to function calls
        functions:
          type:
          - array
          - 'null'
          items: {}
          description: A list of functions the model may generate JSON inputs for
        logit_bias:
          type:
          - object
          - 'null'
          description: |-
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer)
            to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits
            generated by the model prior to sampling. The exact effect will vary per model, but values
            between -1 and 1 should decrease or increase likelihood of selection; values like -100 or
            100 should result in a ban or exclusive selection of the relevant token.
          additionalProperties:
            type: number
            format: float
          propertyNames:
            type: integer
            format: int32
            minimum: 0
        max_completion_tokens:
          type:
          - integer
          - 'null'
          format: int32
          description: The maximum number of tokens to generate in the chat completion
          example: 4096
        max_tokens:
          type:
          - integer
          - 'null'
          format: int32
          description: The maximum number of tokens to generate in the chat completion
          deprecated: true
          example: 4096
        messages:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionMessage'
          description: A list of messages comprising the conversation so far
        model:
          type: string
          description: ID of the model to use
          example: meta-llama/Llama-3.3-70B-Instruct
        n:
          type:
          - integer
          - 'null'
          format: int32
          description: How many chat completion choices to generate for each input message
          example: 1
        parallel_tool_calls:
          type:
          - boolean
          - 'null'
          description: Whether to enable parallel tool calls.
        presence_penalty:
          type:
          - number
          - 'null'
          format: float
          description: |-
            Number between -2.0 and 2.0. Positive values penalize new tokens based on
            whether they appear in the text so far
          example: 0.0
        response_format:
          oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/ResponseFormat'
            description: The format to return the response in
        seed:
          type:
          - integer
          - 'null'
          format: int64
          description: If specified, our system will make a best effort to sample deterministically
          example: 123
        service_tier:
          type:
          - string
          - 'null'
          description: |-
            Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

            If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
            If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
            If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
            When not set, the default behavior is 'auto'.
        stop:
          type:
          - array
          - 'null'
          items:
            type: string
          description: Up to 4 sequences where the API will stop generating further tokens
          example: json(["stop", "halt"])
          default: '[]'
        stream:
          type:
          - boolean
          - 'null'
          description: Whether to stream back partial progress
          example: false
        stream_options:
          oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/StreamOptions'
            description: 'Options for streaming response. Only set this when you set stream: true.'
        temperature:
          type:
          - number
          - 'null'
          format: float
          description: What sampling temperature to use, between 0 and 2
          example: 0.7
        tool_choice:
          oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/ToolChoice'
            description: Controls which (if any) tool the model should use
        tools:
          type:
          - array
          - 'null'
          items:
            $ref: '#/components/schemas/ChatCompletionToolsParam'
          description: A list of tools the model may call
        top_logprobs:
          type:
          - integer
          - 'null'
          format: int32
          description: |-
            An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability.
            logprobs must be set to true if this parameter is used.
          example: 1
        top_p:
          type:
          - number
          - 'null'
          format: float
          description: An alternative to sampling with temperature
          example: 1.0
        user:
          type:
          - string
          - 'null'
          description: A unique identifier representing your end-user
          example: user-1234
    ChatCompletionResponse:
      type: object
      description: |-
        Represents the chat completion response.

        This is used to represent the chat completion response in the chat completion request.
        It can be either a chat completion or a chat completion stream.
      required:
      - id
      - created
      - model
      - choices
      - object
      properties:
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionChoice'
          description: A list of chat completion choices.
        created:
          type: integer
          format: int64
          description: The Unix timestamp (in seconds) of when the chat completion was created.
          example: 1677652288
        id:
          type: string
          description: A unique identifier for the chat completion.
          example: chatcmpl-123
        model:
          type: string
          description: The model used for the chat completion.
          example: meta-llama/Llama-3.3-70B-Instruct
        object:
          type: string
          description: The object of the chat completion.
          example: chat.completion
        service_tier:
          type:
          - string
          - 'null'
          description: The service tier of the chat completion.
        system_fingerprint:
          type:
          - string
          - 'null'
          description: The system fingerprint for the completion, if applicable.
          example: fp_44709d6fcb
        usage:
          oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/CompletionUsage'
            description: Usage statistics for the completion request.
    ChatCompletionStreamResponse:
      type: object
      description: |-
        Represents the chat completion stream response.

        This is used to represent the chat completion stream response in the chat completion request.
        It can be either a chat completion chunk or a chat completion stream.
      required:
      - data
      properties:
        data:
          $ref: '#/components/schemas/ChatCompletionChunk'
          description: The stream of chat completion chunks.
    ChatCompletionToolFunctionParam:
      type: object
      description: A function that can be used in a chat completion.
      required:
      - name
      properties:
        description:
          type:
          - string
          - 'null'
          description: The description of the function.
        name:
          type: string
          description: The name of the function.
        parameters:
          type:
          - object
          - 'null'
          description: The parameters of the function.
          additionalProperties: {}
          propertyNames:
            type: string
        strict:
          type:
          - boolean
          - 'null'
          description: Whether to strictly validate the parameters of the function.
    ChatCompletionToolsParam:
      type: object
      description: A tool that can be used in a chat completion.
      required:
      - type
      - function
      properties:
        function:
          $ref: '#/components/schemas/ChatCompletionToolFunctionParam'
          description: The function that the tool will call.
        type:
          type: string
          description: The type of the tool.
    CompletionUsage:
      type: object
      description: |-
        Represents the completion usage.

        This is used to represent the completion usage in the chat completion request.
        It can be either a completion usage or a completion chunk usage.
      required:
      - prompt_tokens
      - completion_tokens
      - total_tokens
      properties:
        completion_tokens:
          type: integer
          format: int32
          description: Number of tokens in the completion.
          example: 12
        prompt_tokens:
          type: integer
          format: int32
          description: Number of tokens in the prompt.
          example: 9
        prompt_tokens_details:
          oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/PromptTokensDetails'
            description: Details about the prompt tokens.
        total_tokens:
          type: integer
          format: int32
          description: Total number of tokens used (prompt + completion).
          example: 21
    ConfidentialComputeRequest:
      type: object
      description: A request for confidential computation that includes encrypted data and associated cryptographic parameters
      required:
      - ciphertext
      - stack_small_id
      - nonce
      - salt
      - client_dh_public_key
      - node_dh_public_key
      - plaintext_body_hash
      - model_name
      properties:
        ciphertext:
          type: string
          description: The encrypted payload that needs to be processed (base64 encoded)
        client_dh_public_key:
          type: string
          description: Client's public key for Diffie-Hellman key exchange (base64 encoded)
        model_name:
          type: string
          description: Model name
        node_dh_public_key:
          type: string
          description: Node's public key for Diffie-Hellman key exchange (base64 encoded)
        nonce:
          type: string
          description: Cryptographic nonce used for encryption (base64 encoded)
        num_compute_units:
          type:
          - integer
          - 'null'
          format: int64
          description: |-
            Number of compute units to be used for the request, for image generations,
            as this value is known in advance (the number of pixels to generate)
          minimum: 0
        plaintext_body_hash:
          type: string
          description: Hash of the original plaintext body for integrity verification (base64 encoded)
        salt:
          type: string
          description: Salt value used in key derivation (base64 encoded)
        stack_small_id:
          type: integer
          format: int64
          description: Unique identifier for the small stack being used
          minimum: 0
        stream:
          type:
          - boolean
          - 'null'
          description: Indicates whether this is a streaming request
    ConfidentialComputeResponse:
      type: object
      description: Represents a response from a confidential compute request
      required:
      - ciphertext
      - nonce
      properties:
        ciphertext:
          type: string
          description: Encrypted response body (base64 encoded)
        nonce:
          type: string
          description: Nonce used for encryption (base64 encoded)
        response_hash:
          type:
          - string
          - 'null'
          description: Hash of the response body (base64 encoded)
        signature:
          type:
          - string
          - 'null'
          description: Signature of the response body (base64 encoded)
        usage:
          oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/Usage'
            description: Usage statistics for the request
    ConfidentialComputeStreamResponse:
      type: object
      description: Represents a response from a confidential compute request
      required:
      - data
      properties:
        data:
          $ref: '#/components/schemas/ConfidentialComputeResponse'
          description: The stream of chat completion chunks.
    CreateChatCompletionRequest:
      allOf:
      - $ref: '#/components/schemas/ChatCompletionRequest'
      - type: object
        properties:
          stream:
            type:
            - boolean
            - 'null'
            description: Whether to stream back partial progress. Must be false for this request type.
            default: false
      description: |-
        Represents the create chat completion request.

        This is used to represent the create chat completion request in the chat completion request.
        It can be either a chat completion or a chat completion stream.
    CreateChatCompletionStreamRequest:
      allOf:
      - $ref: '#/components/schemas/ChatCompletionRequest'
      - type: object
        required:
        - stream
        properties:
          stream:
            type: boolean
            description: Whether to stream back partial progress. Must be true for this request type.
            default: true
    CreateEmbeddingRequest:
      type: object
      description: Request object for creating embeddings
      required:
      - model
      - input
      properties:
        dimensions:
          type:
          - integer
          - 'null'
          format: int32
          description: The number of dimensions the resulting output embeddings should have.
          minimum: 0
        encoding_format:
          type:
          - string
          - 'null'
          description: |-
            The format to return the embeddings in. Can be "float" or "base64".
            Defaults to "float"
          example: float
        input:
          $ref: '#/components/schemas/EmbeddingInput'
          description: |-
            Input text to get embeddings for. Can be a string or array of strings.
            Each input must not exceed the max input tokens for the model
        model:
          type: string
          description: ID of the model to use.
          example: intfloat/multilingual-e5-large-instruct
        user:
          type:
          - string
          - 'null'
          description: A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
          example: user-1234
    CreateEmbeddingResponse:
      type: object
      description: Response object from creating embeddings
      required:
      - object
      - model
      - data
      - usage
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/EmbeddingObject'
          description: List of embedding objects
        model:
          type: string
          description: The model used for generating embeddings
          example: intfloat/multilingual-e5-large-instruct
        object:
          type: string
          description: The object type, which is always "list"
          example: list
        usage:
          $ref: '#/components/schemas/EmbeddingUsage'
          description: Usage statistics for the request
    CreateImageRequest:
      type: object
      description: Request body for image generation
      required:
      - prompt
      - model
      properties:
        model:
          type: string
          description: The model to use for image generation.
          example: black-forest-labs/FLUX.1-schnell
        n:
          type:
          - integer
          - 'null'
          format: int32
          description: The number of images to generate. Defaults to 1.
          example: 1
          minimum: 0
        prompt:
          type: string
          description: A text description of the desired image(s). The maximum length is 1000 characters.
          example: A cute baby sea otter floating on its back
        quality:
          type:
          - string
          - 'null'
          description: |-
            The quality of the image that will be generated.
            `hd` creates images with finer details and greater consistency across the image.
          example: hd
        response_format:
          type:
          - string
          - 'null'
          description: The format in which the generated images are returned.
          example: url
        size:
          type:
          - string
          - 'null'
          description: The size of the generated images.
          example: 1024x1024
        style:
          type:
          - string
          - 'null'
          description: The style of the generated images.
          example: vivid
        user:
          type:
          - string
          - 'null'
          description: A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
          example: user-1234
    CreateImageResponse:
      type: object
      description: Response format for image generation
      required:
      - created
      - data
      properties:
        created:
          type: integer
          format: int64
          example: 1677649420
        data:
          type: array
          items:
            $ref: '#/components/schemas/ImageData'
    EmbeddingInput:
      oneOf:
      - type: string
        example: The quick brown fox jumped over the lazy dog
      - type: array
        items:
          type: string
        example: '["The quick brown fox", "jumped over the lazy dog"]'
    EmbeddingObject:
      type: object
      description: Individual embedding object in the response
      required:
      - object
      - embedding
      - index
      properties:
        embedding:
          type: array
          items:
            type: number
            format: float
          description: The embedding vector
          example: '[0.0023064255, -0.009327292]'
        index:
          type: integer
          description: Index of the embedding in the list of embeddings
          example: 0
          minimum: 0
        object:
          type: string
          description: The object type, which is always "embedding"
          example: embedding
    EmbeddingUsage:
      type: object
      description: Usage information for the embeddings request
      required:
      - prompt_tokens
      - total_tokens
      properties:
        prompt_tokens:
          type: integer
          format: int32
          description: Number of tokens in the prompt
          example: 8
          minimum: 0
        total_tokens:
          type: integer
          format: int32
          description: Total tokens used in the request
          example: 8
          minimum: 0
    HealthResponse:
      type: object
      required:
      - message
      properties:
        message:
          type: string
          description: The status of the service
    ImageData:
      type: object
      description: Individual image data in the response
      required:
      - url
      properties:
        revised_prompt:
          type:
          - string
          - 'null'
          example: A stunning image of a baby sea otter floating on its back in crystal clear blue water, with gentle ripples surrounding it. The otter's fur appears soft and well-detailed, and its expression is peaceful and content.
        url:
          type: string
          example: https://oaidalleapiprodscus.blob.core.windows.net/private/image.png
    JsonSchemaResponseFormat:
      type: object
      description: |-
        The format to return the response in.

        This is used to represent the format to return the response in in the chat completion request.
        It can be either text, json_object, or json_schema.
      required:
      - name
      properties:
        description:
          type:
          - string
          - 'null'
          description: The description of the response format.
        name:
          type: string
          description: The name of the response format.
        schema:
          description: The JSON schema of the response format.
        strict:
          type:
          - boolean
          - 'null'
          description: Whether to strictly validate the JSON schema.
    MessageContent:
      oneOf:
      - type: string
        description: The text contents of the message.
      - type: array
        items:
          $ref: '#/components/schemas/MessageContentPart'
        description: |-
          An array of content parts with a defined type, each can be of type text or image_url when passing in images.
          You can pass multiple images by adding multiple image_url content parts. Image input is only supported when using the gpt-4o model.
      description: |-
        Represents the content of a message.

        This is used to represent the content of a message in the chat completion request.
        It can be either a text or an array of content parts.
    MessageContentPart:
      oneOf:
      - type: object
        required:
        - type
        - text
        properties:
          text:
            type: string
            description: The text content.
          type:
            type: string
            description: The type of the content part.
      - type: object
        required:
        - type
        - image_url
        properties:
          image_url:
            $ref: '#/components/schemas/MessageContentPartImageUrl'
            description: The image URL.
          type:
            type: string
            description: The type of the content part.
      description: |-
        Represents a part of a message content.

        This is used to represent the content of a message in the chat completion request.
        It can be either a text or an image.
    MessageContentPartImageUrl:
      type: object
      description: |-
        Represents the image URL of a message content part.

        This is used to represent the image URL of a message content part in the chat completion request.
        It can be either a URL or a base64 encoded image data.
      required:
      - url
      properties:
        detail:
          type:
          - string
          - 'null'
          description: Specifies the detail level of the image.
        url:
          type: string
          description: Either a URL of the image or the base64 encoded image data.
    Model:
      type: object
      description: Individual model object in the response
      required:
      - id
      - object
      - created
      - owned_by
      properties:
        created:
          type: integer
          format: int64
          description: Unix timestamp (in seconds) when this model was created
        id:
          type: string
          description: The model identifier
        object:
          type: string
          description: The object type, which is always "model"
        owned_by:
          type: string
          description: Organization that owns the model
    ModelList:
      type: object
      description: Response object for the models listing endpoint
      required:
      - object
      - data
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/Model'
          description: List of model objects
        object:
          type: string
          description: The object type, which is always "list"
    NodePublicAddressAssignment:
      type: object
      description: |-
        Represents the payload for the node public address registration request.

        This struct represents the payload for the node public address registration request.
      required:
      - node_small_id
      - public_address
      - country
      properties:
        country:
          type: string
          description: The country of the node
        node_small_id:
          type: integer
          format: int64
          description: Unique small integer identifier for the node
          minimum: 0
        public_address:
          type: string
          description: The public address of the node
    NodesCreateLockRequest:
      type: object
      description: Request body for creating a node lock
      required:
      - model
      properties:
        model:
          type: string
          description: The model to lock a node for
    NodesCreateLockResponse:
      type: object
      description: |-
        The response body for selecting a node's public key for encryption
        from a client. The client will use the provided public key to encrypt
        the request and send it back to the proxy. The proxy will then route this
        request to the selected node.
      required:
      - public_key
      - node_small_id
      - stack_small_id
      properties:
        node_small_id:
          type: integer
          format: int64
          description: The node small id for the selected node
          minimum: 0
        public_key:
          type: string
          description: The public key for the selected node, base64 encoded
        stack_entry_digest:
          type:
          - string
          - 'null'
          description: Transaction digest for the transaction that acquires the stack entry, if any
        stack_small_id:
          type: integer
          format: int64
          description: The stack small id to which an available stack entry was acquired, for the selected node
          minimum: 0
    NodesCreateRequest:
      type: object
      description: Represents the payload for the node public address registration request.
      required:
      - data
      - signature
      properties:
        data:
          $ref: '#/components/schemas/NodePublicAddressAssignment'
          description: The data required to register a node's public address
        signature:
          type: string
          description: The signature of the data base 64 encoded
    NodesCreateResponse:
      type: object
      required:
      - message
      properties:
        message:
          type: string
          description: The message of the response
    PromptTokensDetails:
      type: object
      description: |-
        Represents the prompt tokens details.

        This is used to represent the prompt tokens details in the chat completion request.
        It can be either a prompt tokens details or a prompt tokens details choice.
      required:
      - cached_tokens
      properties:
        cached_tokens:
          type: integer
          format: int32
          description: Number of tokens in the prompt that were cached.
          example: 1
    ResponseFormat:
      type: object
      description: |-
        The format to return the response in.

        This is used to represent the format to return the response in in the chat completion request.
        It can be either text, json_object, or json_schema.
      required:
      - type
      properties:
        json_schema:
          oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/JsonSchemaResponseFormat'
            description: The JSON schema of the response format.
        type:
          $ref: '#/components/schemas/ResponseFormatType'
          description: The type of the response format.
    ResponseFormatType:
      type: string
      description: The format to return the response in.
      enum:
      - text
      - json_object
      - json_schema
    StopReason:
      oneOf:
      - type: object
        required:
        - Int
        properties:
          Int:
            type: integer
            format: int32
            minimum: 0
      - type: object
        required:
        - String
        properties:
          String:
            type: string
      description: |-
        Represents the stop reason.

        This is used to represent the stop reason in the chat completion request.
        It can be either a stop reason or a stop reason choice.
    StreamOptions:
      type: object
      description: Specifies the stream options for the request.
      properties:
        include_usage:
          type:
          - boolean
          - 'null'
          description: |-
            If set, an additional chunk will be streamed before the data: [DONE] message.
            The usage field on this chunk shows the token usage statistics for the entire request, and the choices field
            will always be an empty array. All other chunks will also include a usage field, but with a null value.
    Tool:
      type: object
      description: |-
        Represents the tool that the model called.

        This is used to represent the tool that the model called in the chat completion request.
        It can be either a function or a tool.
      required:
      - type
      - function
      properties:
        function:
          $ref: '#/components/schemas/ToolFunction'
          description: The function that the model called.
        type:
          type: string
          description: The type of the tool. Currently, only function is supported.
    ToolCall:
      type: object
      description: |-
        Represents the tool call that the model made.

        This is used to represent the tool call that the model made in the chat completion request.
        It can be either a function or a tool.
      required:
      - id
      - type
      - function
      properties:
        function:
          $ref: '#/components/schemas/ToolCallFunction'
          description: The function that the model called.
        id:
          type: string
          description: The ID of the tool call.
        type:
          type: string
          description: The type of the tool. Currently, only function is supported.
    ToolCallFunction:
      type: object
      description: |-
        Represents the function that the model called.

        This is used to represent the function that the model called in the chat completion request.
        It can be either a function or a tool call.
      required:
      - name
      - arguments
      properties:
        arguments:
          type: string
          description: |-
            The arguments to call the function with, as generated by the model in JSON format.
            Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema.
            Validate the arguments in your code before calling your function.
        name:
          type: string
          description: The name of the function to call.
    ToolChoice:
      oneOf:
      - $ref: '#/components/schemas/ToolChoiceLiteral'
      - $ref: '#/components/schemas/ChatCompletionNamedToolChoiceParam'
      description: |-
        A tool choice that can be used in a chat completion.

        This is used to represent the tool choice in the chat completion request.
        It can be either a literal tool choice or a named tool choice.
    ToolChoiceLiteral:
      type: string
      description: |-
        A literal tool choice that can be used in a chat completion.

        This is used to represent the literal tool choice in the chat completion request.
        It can be either none or auto.
      enum:
      - none
      - auto
    ToolFunction:
      type: object
      description: |-
        Represents the function that the model called.

        This is used to represent the function that the model called in the chat completion request.
        It can be either a function or a tool.
      required:
      - name
      properties:
        description:
          type:
          - string
          - 'null'
          description: Description of the function to call.
        name:
          type: string
          description: The name of the function to call.
        parameters:
          description: The arguments to call the function with, as generated by the model in JSON format.
        strict:
          type:
          - boolean
          - 'null'
          description: |-
            Whether to enable strict schema adherence when generating the function call. If set to true, the
            model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true
    Usage:
      type: object
      description: Represents usage statistics for a confidential compute request
      required:
      - prompt_tokens
      - total_tokens
      properties:
        completion_tokens:
          type:
          - integer
          - 'null'
          format: int64
          description: |-
            Number of compute units used
            NOTE: This is not used for the embeddings endpoint
          minimum: 0
        completion_tokens_details:
          description: Details about the completion tokens
        prompt_tokens:
          type: integer
          format: int64
          description: Number of compute units used
          minimum: 0
        total_tokens:
          type: integer
          format: int64
          description: Number of compute units used
          minimum: 0
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
tags:
- name: Chat
  description: OpenAI's API chat completions v1 endpoint
- name: Confidential Chat
  description: Atoma's API confidential chat completions v1 endpoint
- name: Confidential Embeddings
  description: Atoma's API confidential embeddings v1 endpoint
- name: Confidential Images
  description: Atoma's API confidential images v1 endpoint
- name: Embeddings
  description: OpenAI's API embeddings v1 endpoint
- name: Health
  description: Health check
- name: Images
  description: OpenAI's API images v1 endpoint
- name: Models
  description: OpenAI's API models v1 endpoint
- name: Nodes
  description: Nodes Management
- name: Node Public Key Selection
  description: Node public key selection
x-speakeasy-name-override:
- operationId: chat_completions_create
  methodNameOverride: create
- operationId: chat_completions_create_stream
  methodNameOverride: create_stream
- operationId: confidential_chat_completions_create
  methodNameOverride: create
- operationId: confidential_chat_completions_create_stream
  methodNameOverride: create_stream
- operationId: embeddings_create
  methodNameOverride: create
- operationId: confidential_embeddings_create
  methodNameOverride: create
- operationId: image_generations_create
  methodNameOverride: generate
- operationId: confidential_image_generations_create
  methodNameOverride: generate
