openapi: 3.1.0
info:
  title: atoma-proxy
  description: ''
  license:
    name: Apache-2.0
    identifier: Apache-2.0
  version: 0.1.0
servers:
- url: https://api.atoma.network
paths:
  /v1/chat/completions:
    post:
      tags:
      - Chat
      summary: Create chat completion
      description: |-
        This function processes chat completion requests by determining whether to use streaming
        or non-streaming response handling based on the request payload. For streaming requests,
        it configures additional options to track token usage.

        ## Returns

        Returns a Response containing either:
        - A streaming SSE connection for real-time completions
        - A single JSON response for non-streaming completions

        ## Errors

        Returns an error status code if:
        - The request processing fails
        - The streaming/non-streaming handlers encounter errors
        - The underlying inference service returns an error
      operationId: chat_completions_create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
        required: true
      responses:
        '200':
          description: Chat completions
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /v1/chat/completions#stream:
    post:
      tags:
      - Chat
      operationId: chat_completions_create_stream
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionStreamRequest'
        required: true
      responses:
        '200':
          description: Chat completions
          content:
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ChatCompletionStreamResponse'
              x-speakeasy-sse-sentinel: '[DONE]'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /v1/confidential/chat/completions:
    post:
      tags:
      - Confidential Chat
      summary: Create confidential chat completion
      description: |-
        This handler processes chat completion requests in a confidential manner, providing additional
        encryption and security measures for sensitive data processing. It supports both streaming and
        non-streaming responses while maintaining data confidentiality through AEAD encryption and TEE hardware,
        for full private AI compute.

        ## Returns

        Returns a `Result` containing either:
        * An HTTP response with the chat completion result
        * A streaming SSE connection for real-time completions
        * An `AtomaProxyError` error if the request processing fails

        ## Errors

        Returns `AtomaProxyError::InvalidBody` if:
        * The 'stream' field is missing or invalid in the payload

        Returns `AtomaProxyError::InternalError` if:
        * The inference service request fails
        * Response processing encounters errors
        * State manager updates fail

        ## Security Features

        * Utilizes AEAD encryption for request/response data
        * Supports TEE (Trusted Execution Environment) processing
        * Implements secure key exchange using X25519
        * Maintains confidentiality throughout the request lifecycle
      operationId: confidential_chat_completions_create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ConfidentialComputeRequest'
        required: true
      responses:
        '200':
          description: Confidential chat completions
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConfidentialComputeResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /v1/confidential/chat/completions#stream:
    post:
      tags:
      - Confidential Chat
      operationId: confidential_chat_completions_create_stream
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ConfidentialComputeRequest'
        required: true
      responses:
        '200':
          description: Chat completions
          content:
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ConfidentialComputeStreamResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /v1/confidential/embeddings:
    post:
      tags:
      - Confidential Embeddings
      summary: Create confidential embeddings
      description: |-
        This endpoint follows the OpenAI API format for generating vector embeddings from input text,
        but with confidential processing (through AEAD encryption and TEE hardware).
        The handler receives pre-processed metadata from middleware and forwards the request to
        the selected node.

        ## Returns
        * `Ok(Response)` - The embeddings response from the processing node
        * `Err(AtomaProxyError)` - An error status code if any step fails

        ## Errors
        * `INTERNAL_SERVER_ERROR` - Processing or node communication failures
      operationId: confidential_embeddings_create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ConfidentialComputeRequest'
        required: true
      responses:
        '200':
          description: Confidential embeddings generated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConfidentialComputeResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /v1/confidential/images/generations:
    post:
      tags:
      - Confidential Images
      summary: Create confidential image
      description: |-
        This handler processes image generation requests in a confidential manner, providing additional
        encryption and security measures for sensitive data processing. It supports both streaming and
        non-streaming responses while maintaining data confidentiality through AEAD encryption and TEE hardware,
        for full private AI compute.
      operationId: confidential_image_generations_create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ConfidentialComputeRequest'
        required: true
      responses:
        '200':
          description: Image generations
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConfidentialComputeResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /v1/embeddings:
    post:
      tags:
      - Embeddings
      summary: Create embeddings
      description: |-
        This endpoint follows the OpenAI API format for generating vector embeddings from input text.
        The handler receives pre-processed metadata from middleware and forwards the request to
        the selected node.

        # Returns
        * `Ok(Response)` - The embeddings response from the processing node
        * `Err(AtomaProxyError)` - An error status code if any step fails

        ## Errors
        * `INTERNAL_SERVER_ERROR` - Processing or node communication failures
      operationId: embeddings_create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEmbeddingRequest'
        required: true
      responses:
        '200':
          description: Embeddings generated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateEmbeddingResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /health:
    get:
      tags:
      - Health
      summary: Health
      operationId: health
      responses:
        '200':
          description: Service is healthy
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HealthResponse'
        '500':
          description: Service is unhealthy
  /v1/images/generations:
    post:
      tags:
      - Images
      summary: Create image
      description: |-
        This endpoint processes requests to generate images using AI models by forwarding them
        to the appropriate AI node. The request metadata and compute units have already been
        validated by middleware before reaching this handler.

        ## Errors
        * Returns various status codes based on the underlying `handle_image_generation_response`:
          - `INTERNAL_SERVER_ERROR` - If there's an error communicating with the AI node
      operationId: image_generations_create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateImageRequest'
        required: true
      responses:
        '200':
          description: Image generations
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateImageResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '500':
          description: Internal server error
      security:
      - bearerAuth: []
  /v1/models:
    get:
      tags:
      - Models
      summary: List models
      description: |-
        This endpoint mimics the OpenAI models endpoint format, returning a list of
        available models with their associated metadata. Each model includes standard
        OpenAI-compatible fields to ensure compatibility with existing OpenAI client libraries.
      operationId: models_list
      responses:
        '200':
          description: List of available models
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelList'
        '500':
          description: Failed to retrieve list of available models
      security:
      - bearerAuth: []
  /v1/nodes:
    post:
      tags:
      - Nodes
      summary: Create node
      description: |-
        This endpoint allows nodes to register or update their public address in the system.
        When a node comes online or changes its address, it can use this endpoint to ensure
        the system has its current address for routing requests.

        ## Errors

        Returns various `AtomaProxyError` variants:
        * `MissingHeader` - If the signature header is missing
        * `InvalidHeader` - If the signature header is malformed
        * `InvalidBody` - If:
          - The request body cannot be read
          - The signature is invalid
          - The body cannot be parsed
          - The sui address doesn't match the signature
        * `InternalError` - If:
          - The state manager channel is closed
          - The registration event cannot be sent
          - Node Sui address lookup fails
      operationId: nodes_create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/NodesCreateRequest'
        required: true
      responses:
        '200':
          description: Node public address registered successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/NodesCreateResponse'
        '500':
          description: Failed to register node public address
  /v1/nodes/lock:
    post:
      tags:
      - Nodes
      summary: Create a node lock for confidential compute
      description: |-
        This endpoint attempts to find a suitable node and retrieve its public key for encryption
        through a two-step process:

        1. First, it tries to select an existing node with a public key directly.
        2. If no node is immediately available, it falls back to finding the cheapest compatible node
           and acquiring a new stack entry for it.

        This endpoint is specifically designed for confidential compute scenarios where
        requests need to be encrypted before being processed by nodes.

        ## Errors
          - `INTERNAL_SERVER_ERROR` - Communication errors or missing node public keys
          - `SERVICE_UNAVAILABLE` - No nodes available for confidential compute
      operationId: nodes_create_lock
      requestBody:
        description: The model to lock a node for
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/NodesCreateLockRequest'
        required: true
      responses:
        '200':
          description: Node DH public key requested successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/NodesCreateLockResponse'
        '500':
          description: Failed to request node DH public key
        '503':
          description: No node found for model with confidential compute enabled for requested model
      security:
      - bearerAuth: []
components:
  schemas:
    ChatCompletionChoice:
      type: object
      required:
      - index
      - message
      properties:
        finish_reason:
          type:
          - string
          - 'null'
          description: The reason the chat completion was finished.
          example: stop
        index:
          type: integer
          format: int32
          description: The index of this choice in the list of choices.
          example: 0
        logprobs:
          description: Log probability information for the choice, if applicable.
        message:
          $ref: '#/components/schemas/ChatCompletionMessage'
          description: The chat completion message.
    ChatCompletionChunk:
      type: object
      required:
      - id
      - created
      - model
      - choices
      properties:
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionChunkChoice'
          description: A list of chat completion chunk choices.
        created:
          type: integer
          format: int64
          description: The Unix timestamp (in seconds) of when the chunk was created.
          example: 1677652288
        id:
          type: string
          description: A unique identifier for the chat completion chunk.
          example: chatcmpl-123
        model:
          type: string
          description: The model used for the chat completion.
          example: meta-llama/Llama-3.3-70B-Instruct
    ChatCompletionChunkChoice:
      type: object
      required:
      - index
      - delta
      properties:
        delta:
          $ref: '#/components/schemas/ChatCompletionChunkDelta'
          description: The chat completion delta message for streaming.
        finish_reason:
          type:
          - string
          - 'null'
          description: The reason the chat completion was finished, if applicable.
          example: stop
        index:
          type: integer
          format: int32
          description: The index of this choice in the list of choices.
          example: 0
    ChatCompletionChunkDelta:
      type: object
      properties:
        content:
          type:
          - string
          - 'null'
          description: The content of the message, if present in this chunk.
          example: Hello
        function_call:
          description: The function call information, if present in this chunk.
        role:
          type:
          - string
          - 'null'
          description: The role of the message author, if present in this chunk.
          example: assistant
        tool_calls:
          type:
          - array
          - 'null'
          items: {}
          description: The tool calls information, if present in this chunk.
    ChatCompletionMessage:
      type: object
      required:
      - role
      - content
      properties:
        content:
          type: string
          description: The contents of the message
          example: Hello! How can you help me today?
        name:
          type:
          - string
          - 'null'
          description: The name of the author of this message
          example: john_doe
        role:
          type: string
          description: 'The role of the message author. One of: "system", "user", "assistant", "tool", or "function"'
          example: user
    ChatCompletionRequest:
      type: object
      required:
      - model
      - messages
      properties:
        frequency_penalty:
          type:
          - number
          - 'null'
          format: float
          description: |-
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their
            existing frequency in the text so far
          example: 0.0
        function_call:
          description: Controls how the model responds to function calls
        functions:
          type:
          - array
          - 'null'
          items: {}
          description: A list of functions the model may generate JSON inputs for
        logit_bias:
          type:
          - object
          - 'null'
          description: Modify the likelihood of specified tokens appearing in the completion
          additionalProperties:
            type: number
            format: float
          propertyNames:
            type: string
        max_tokens:
          type:
          - integer
          - 'null'
          format: int32
          description: The maximum number of tokens to generate in the chat completion
          example: 2048
        messages:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionMessage'
          description: A list of messages comprising the conversation so far
        model:
          type: string
          description: ID of the model to use
          example: meta-llama/Llama-3.3-70B-Instruct
        n:
          type:
          - integer
          - 'null'
          format: int32
          description: How many chat completion choices to generate for each input message
          example: 1
        presence_penalty:
          type:
          - number
          - 'null'
          format: float
          description: |-
            Number between -2.0 and 2.0. Positive values penalize new tokens based on
            whether they appear in the text so far
          example: 0.0
        response_format:
          description: The format to return the response in
        seed:
          type:
          - integer
          - 'null'
          format: int64
          description: If specified, our system will make a best effort to sample deterministically
          example: 123
        stop:
          type:
          - array
          - 'null'
          items:
            type: string
          description: Up to 4 sequences where the API will stop generating further tokens
          example: json(["stop", "halt"])
          default: '[]'
        stream:
          type:
          - boolean
          - 'null'
          description: Whether to stream back partial progress
          example: false
        temperature:
          type:
          - number
          - 'null'
          format: float
          description: What sampling temperature to use, between 0 and 2
          example: 0.7
        tool_choice:
          description: Controls which (if any) tool the model should use
        tools:
          type:
          - array
          - 'null'
          items: {}
          description: A list of tools the model may call
        top_p:
          type:
          - number
          - 'null'
          format: float
          description: An alternative to sampling with temperature
          example: 1.0
        user:
          type:
          - string
          - 'null'
          description: A unique identifier representing your end-user
          example: user-1234
    ChatCompletionResponse:
      type: object
      required:
      - id
      - created
      - model
      - choices
      properties:
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionChoice'
          description: A list of chat completion choices.
        created:
          type: integer
          format: int64
          description: The Unix timestamp (in seconds) of when the chat completion was created.
          example: 1677652288
        id:
          type: string
          description: A unique identifier for the chat completion.
          example: chatcmpl-123
        model:
          type: string
          description: The model used for the chat completion.
          example: meta-llama/Llama-3.3-70B-Instruct
        system_fingerprint:
          type:
          - string
          - 'null'
          description: The system fingerprint for the completion, if applicable.
          example: fp_44709d6fcb
        usage:
          oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/CompletionUsage'
            description: Usage statistics for the completion request.
    ChatCompletionStreamResponse:
      type: object
      required:
      - data
      properties:
        data:
          $ref: '#/components/schemas/ChatCompletionChunk'
          description: The stream of chat completion chunks.
    CompletionUsage:
      type: object
      required:
      - prompt_tokens
      - completion_tokens
      - total_tokens
      properties:
        completion_tokens:
          type: integer
          format: int32
          description: Number of tokens in the completion.
          example: 12
        prompt_tokens:
          type: integer
          format: int32
          description: Number of tokens in the prompt.
          example: 9
        total_tokens:
          type: integer
          format: int32
          description: Total number of tokens used (prompt + completion).
          example: 21
    ConfidentialComputeRequest:
      type: object
      description: A request for confidential computation that includes encrypted data and associated cryptographic parameters
      required:
      - ciphertext
      - stack_small_id
      - nonce
      - salt
      - client_dh_public_key
      - node_dh_public_key
      - plaintext_body_hash
      - model_name
      properties:
        ciphertext:
          type: string
          description: The encrypted payload that needs to be processed (base64 encoded)
        client_dh_public_key:
          type: string
          description: Client's public key for Diffie-Hellman key exchange (base64 encoded)
        model_name:
          type: string
          description: Model name
        node_dh_public_key:
          type: string
          description: Node's public key for Diffie-Hellman key exchange (base64 encoded)
        nonce:
          type: string
          description: Cryptographic nonce used for encryption (base64 encoded)
        num_compute_units:
          type:
          - integer
          - 'null'
          format: int64
          description: |-
            Number of compute units to be used for the request, for image generations,
            as this value is known in advance (the number of pixels to generate)
          minimum: 0
        plaintext_body_hash:
          type: string
          description: Hash of the original plaintext body for integrity verification (base64 encoded)
        salt:
          type: string
          description: Salt value used in key derivation (base64 encoded)
        stack_small_id:
          type: integer
          format: int64
          description: Unique identifier for the small stack being used
          minimum: 0
        stream:
          type:
          - boolean
          - 'null'
          description: Indicates whether this is a streaming request
    ConfidentialComputeResponse:
      type: object
      description: Represents a response from a confidential compute request
      required:
      - ciphertext
      - nonce
      properties:
        ciphertext:
          type: string
          description: Encrypted response body (base64 encoded)
        nonce:
          type: string
          description: Nonce used for encryption (base64 encoded)
        response_hash:
          type:
          - string
          - 'null'
          description: Hash of the response body (base64 encoded)
        signature:
          type:
          - string
          - 'null'
          description: Signature of the response body (base64 encoded)
        usage:
          oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/Usage'
            description: Usage statistics for the request
    ConfidentialComputeStreamResponse:
      type: object
      description: Represents a response from a confidential compute request
      required:
      - data
      properties:
        data:
          $ref: '#/components/schemas/ConfidentialComputeResponse'
          description: The stream of chat completion chunks.
    CreateChatCompletionRequest:
      allOf:
      - $ref: '#/components/schemas/ChatCompletionRequest'
      - type: object
        properties:
          stream:
            type:
            - boolean
            - 'null'
            description: Whether to stream back partial progress. Must be false for this request type.
            default: false
    CreateChatCompletionStreamRequest:
      allOf:
      - $ref: '#/components/schemas/ChatCompletionRequest'
      - type: object
        required:
        - stream
        properties:
          stream:
            type: boolean
            description: Whether to stream back partial progress. Must be true for this request type.
            default: true
    CreateEmbeddingRequest:
      type: object
      description: Request object for creating embeddings
      required:
      - model
      - input
      properties:
        dimensions:
          type:
          - integer
          - 'null'
          format: int32
          description: The number of dimensions the resulting output embeddings should have.
          minimum: 0
        encoding_format:
          type:
          - string
          - 'null'
          description: |-
            The format to return the embeddings in. Can be "float" or "base64".
            Defaults to "float"
          example: float
        input:
          $ref: '#/components/schemas/EmbeddingInput'
          description: |-
            Input text to get embeddings for. Can be a string or array of strings.
            Each input must not exceed the max input tokens for the model
        model:
          type: string
          description: ID of the model to use.
          example: intfloat/multilingual-e5-large-instruct
        user:
          type:
          - string
          - 'null'
          description: A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
          example: user-1234
    CreateEmbeddingResponse:
      type: object
      description: Response object from creating embeddings
      required:
      - object
      - model
      - data
      - usage
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/EmbeddingObject'
          description: List of embedding objects
        model:
          type: string
          description: The model used for generating embeddings
          example: intfloat/multilingual-e5-large-instruct
        object:
          type: string
          description: The object type, which is always "list"
          example: list
        usage:
          $ref: '#/components/schemas/EmbeddingUsage'
          description: Usage statistics for the request
    CreateImageRequest:
      type: object
      description: Request body for image generation
      required:
      - prompt
      - model
      properties:
        model:
          type: string
          description: The model to use for image generation.
          example: black-forest-labs/FLUX.1-schnell
        n:
          type:
          - integer
          - 'null'
          format: int32
          description: The number of images to generate. Defaults to 1.
          example: 1
          minimum: 0
        prompt:
          type: string
          description: A text description of the desired image(s). The maximum length is 1000 characters.
          example: A cute baby sea otter floating on its back
        quality:
          type:
          - string
          - 'null'
          description: |-
            The quality of the image that will be generated.
            `hd` creates images with finer details and greater consistency across the image.
          example: hd
        response_format:
          type:
          - string
          - 'null'
          description: The format in which the generated images are returned.
          example: url
        size:
          type:
          - string
          - 'null'
          description: The size of the generated images.
          example: 1024x1024
        style:
          type:
          - string
          - 'null'
          description: The style of the generated images.
          example: vivid
        user:
          type:
          - string
          - 'null'
          description: A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
          example: user-1234
    CreateImageResponse:
      type: object
      description: Response format for image generation
      required:
      - created
      - data
      properties:
        created:
          type: integer
          format: int64
          example: 1677649420
        data:
          type: array
          items:
            $ref: '#/components/schemas/ImageData'
    EmbeddingInput:
      oneOf:
      - type: string
        example: The quick brown fox jumped over the lazy dog
      - type: array
        items:
          type: string
        example: '["The quick brown fox", "jumped over the lazy dog"]'
    EmbeddingObject:
      type: object
      description: Individual embedding object in the response
      required:
      - object
      - embedding
      - index
      properties:
        embedding:
          type: array
          items:
            type: number
            format: float
          description: The embedding vector
          example: '[0.0023064255, -0.009327292]'
        index:
          type: integer
          description: Index of the embedding in the list of embeddings
          example: 0
          minimum: 0
        object:
          type: string
          description: The object type, which is always "embedding"
          example: embedding
    EmbeddingUsage:
      type: object
      description: Usage information for the embeddings request
      required:
      - prompt_tokens
      - total_tokens
      properties:
        prompt_tokens:
          type: integer
          format: int32
          description: Number of tokens in the prompt
          example: 8
          minimum: 0
        total_tokens:
          type: integer
          format: int32
          description: Total tokens used in the request
          example: 8
          minimum: 0
    HealthResponse:
      type: object
      required:
      - message
      properties:
        message:
          type: string
          description: The status of the service
    ImageData:
      type: object
      description: Individual image data in the response
      required:
      - url
      properties:
        revised_prompt:
          type:
          - string
          - 'null'
          example: A stunning image of a baby sea otter floating on its back in crystal clear blue water, with gentle ripples surrounding it. The otter's fur appears soft and well-detailed, and its expression is peaceful and content.
        url:
          type: string
          example: https://oaidalleapiprodscus.blob.core.windows.net/private/image.png
    Model:
      type: object
      description: Individual model object in the response
      required:
      - id
      - object
      - created
      - owned_by
      properties:
        created:
          type: integer
          format: int64
          description: Unix timestamp (in seconds) when this model was created
        id:
          type: string
          description: The model identifier
        object:
          type: string
          description: The object type, which is always "model"
        owned_by:
          type: string
          description: Organization that owns the model
    ModelList:
      type: object
      description: Response object for the models listing endpoint
      required:
      - object
      - data
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/Model'
          description: List of model objects
        object:
          type: string
          description: The object type, which is always "list"
    NodePublicAddressAssignment:
      type: object
      description: |-
        Represents the payload for the node public address registration request.

        This struct represents the payload for the node public address registration request.
      required:
      - node_small_id
      - public_address
      - country
      properties:
        country:
          type: string
          description: The country of the node
        node_small_id:
          type: integer
          format: int64
          description: Unique small integer identifier for the node
          minimum: 0
        public_address:
          type: string
          description: The public address of the node
    NodesCreateLockRequest:
      type: object
      description: Request body for creating a node lock
      required:
      - model
      properties:
        model:
          type: string
          description: The model to lock a node for
    NodesCreateLockResponse:
      type: object
      description: |-
        The response body for selecting a node's public key for encryption
        from a client. The client will use the provided public key to encrypt
        the request and send it back to the proxy. The proxy will then route this
        request to the selected node.
      required:
      - public_key
      - node_small_id
      - stack_small_id
      properties:
        node_small_id:
          type: integer
          format: int64
          description: The node small id for the selected node
          minimum: 0
        public_key:
          type: string
          description: The public key for the selected node, base64 encoded
        stack_entry_digest:
          type:
          - string
          - 'null'
          description: Transaction digest for the transaction that acquires the stack entry, if any
        stack_small_id:
          type: integer
          format: int64
          description: The stack small id to which an available stack entry was acquired, for the selected node
          minimum: 0
    NodesCreateRequest:
      type: object
      description: Represents the payload for the node public address registration request.
      required:
      - data
      - signature
      properties:
        data:
          $ref: '#/components/schemas/NodePublicAddressAssignment'
          description: The data required to register a node's public address
        signature:
          type: string
          description: The signature of the data base 64 encoded
    NodesCreateResponse:
      type: object
      required:
      - message
      properties:
        message:
          type: string
          description: The message of the response
    Usage:
      type: object
      description: Represents usage statistics for a confidential compute request
      required:
      - prompt_tokens
      - total_tokens
      properties:
        completion_tokens:
          type:
          - integer
          - 'null'
          format: int64
          description: |-
            Number of compute units used
            NOTE: This is not used for the embeddings endpoint
          minimum: 0
        completion_tokens_details:
          description: Details about the completion tokens
        prompt_tokens:
          type: integer
          format: int64
          description: Number of compute units used
          minimum: 0
        total_tokens:
          type: integer
          format: int64
          description: Number of compute units used
          minimum: 0
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
tags:
- name: Chat
  description: OpenAI's API chat completions v1 endpoint
- name: Confidential Chat
  description: Atoma's API confidential chat completions v1 endpoint
- name: Confidential Embeddings
  description: Atoma's API confidential embeddings v1 endpoint
- name: Confidential Images
  description: Atoma's API confidential images v1 endpoint
- name: Embeddings
  description: OpenAI's API embeddings v1 endpoint
- name: Health
  description: Health check
- name: Images
  description: OpenAI's API images v1 endpoint
- name: Models
  description: OpenAI's API models v1 endpoint
- name: Nodes
  description: Nodes Management
- name: Node Public Key Selection
  description: Node public key selection
x-speakeasy-name-override:
- operationId: chat_completions_create
  methodNameOverride: create
- operationId: chat_completions_create_stream
  methodNameOverride: create_stream
- operationId: confidential_chat_completions_create
  methodNameOverride: create
- operationId: confidential_chat_completions_create_stream
  methodNameOverride: create_stream
- operationId: embeddings_create
  methodNameOverride: create
- operationId: confidential_embeddings_create
  methodNameOverride: create
- operationId: image_generations_create
  methodNameOverride: generate
- operationId: confidential_image_generations_create
  methodNameOverride: generate
